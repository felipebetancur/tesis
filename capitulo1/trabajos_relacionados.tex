\subsection{Trabajos relacionados}

	\RC{Por el momento sólo agrego trabajos relacionados sin estructurar bien la sección}
	
	Se han propuesto muchos enfoques para afrontar el problema del reconocimiento de texto en imágenes naturales. De Campos et al. en \cite{dCBV09} comparan la performance de varios clasificadores (dentro de los cuales hay un motor de OCR comercial\footnote{http://abbyy.com/finereader}) sobre un dataset que ellos mismos crearon llamado \textit{Chars74K} y es el dataset sobre el que corren varios experimentos de este trabajo. Las conclusiones del trabajo destacan la dificultad que tienen los motores de OCR al momento de clasificar caracteres en imágenes naturales. Además, remarcan los beneficios de usar datos sintéticos como fuentes para el entrenamiento los cuales logran un porcentaje de reconocimiento muy similar al obtenido con imagenes reales. También realizan experimentos sobre un conjunto de imágenes de caracteres manuscritos, sin embargo, no logran obtener buenos resultados en comparación con los otros experimentos. 
	
	Otro enfoque lo proponen B. Gatos et al. en \cite{GPP03}. El mismo, consiste en una nueva metodología que ayuda a la detección, la segmentación y el reconocimiento automático de texto en imágenes naturales. Básicamente, la metodología consiste en lograr una eficiente binarización de las imágenes naturales. Para esto, dada una imagen natural, generan dos imágenes nuevas a partir de la original, la primera es una representación en escala de grises y la segunda es la versión invertida de la primera. Posteriormente, se les aplican diferentes técnicas para mejorarlas y así obtener la imagen binaria. Luego, utilizan una función de decisión para elegir que imagen contiene información de texto y a dicha imagen se le realiza un post-procesamiento para eliminar el ruido existente y mejorar la calidad. Después se realiza la detección de las áreas que contienen texto para poder utilizar finalmente el motor de OCR. Uno de los problemas que se desprenden de este enfoque es que al depender de un motor de OCR, el procesamiento que se realiza a la imagen tiene que ser muy bueno ya que la mayoría de las imágenes no son sacadas en las mejores condiciones (p.ej., pobre iluminación, falta de foco, etc).

	L. Neumann y J. Matas \cite{LNJM} se diferencian de los enfoques tradicionales que constan de pipelines de procesamiento y lo reemplaza con un marco de trabajo que consta en la verificación de hipótesis procesando de manera simultaneas múltiples lineas de texto. Además usan fuentes sintéticas como conjunto de entrenamiento, pero una particularidad de este enfoque es que a ninguna de estas fuentes se les aplican transformaciones afines o rotaciones.
	