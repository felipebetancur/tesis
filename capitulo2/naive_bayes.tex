\subsubsection{Clasificador Na\"{i}ve Bayes}

	Es un clasificador probabilístico basado en la aplicación del teorema de Bayes con una fuerte suposición de independencia (naive). En términos simples, un clasificador naive Bayes asume que la presencia o ausencia de una característica particular está relacionada con la presencia o ausencia de cualquier otra característica. Este tipo de clasificador considera que cada una de estas características contribuye independientemente a la probabilidad de que un elemento sea de una clase particular, independientemente de la presencia o ausencia de otras características. Por ejemplo, una fruta puede ser considerada una manzana si es roja, redonda y de 7cm de diámetro aproximadamente.

	El modelo para un clasificador es:
		$$p(C \vert F_1,\dots,F_n)$$
	sobre una variable dependiente C, con un pequeño número de resultados (o clases). Esta variable está condicionada por varias variables independientes desde $F_1$ a $F_n$. El problema es que si el número $n$ de variables independientes es grande (o cuando éstas pueden tomar muchos valores), entonces basar este modelo en tablas de probabilidad se vuelve imposible. Por lo tanto el modelo se reformula para hacerlo más manejable:
Usando el teorema de Bayes se escribe:
		\begin{align*}
		p(C \vert F_1,\dots,F_n) = \frac{p(C) \ p(F_1,\dots,F_n\vert C)}{p(F_1,\dots,F_n)}.
		\end{align*}
		que puede ser reescrita como sigue, aplicando repetidamente la definición de probabilidad condicional:
		\begin{align}
		p(C, F_1, \dots, F_n)
		&= p(C) \ p(F_1,\dots,F_n\vert C) \\
		&= p(C) \ p(F_1\vert C) \ p(F_2,\dots,F_n\vert C, F_1) \\
		&= p(C) \ p(F_1\vert C) \ p(F_2\vert C, F_1) \ p(F_3,\dots,F_n\vert C, F_1, F_2)
		\end{align}
		... y así sucesivamente. Ahora es cuando la asunción "na\"{i}ve" de independencia condicional entra en juego: se asume que cada $F_i$ es independiente de cualquier otra $F_j$ para $j \neq i$. Esto significa que
		\begin{align*}
		p(F_i \vert C, F_j) = p(F_i \vert C)
		\end{align*}
		por lo que la probabilidad compuesta puede expresarse como
		\begin{align*}
		p(C, F_1, \dots, F_n) 
		&= p(C) \ p(F_1\vert C) \ p(F_2\vert C) \ p(F_3\vert C) \dots \\
		&= p(C) \prod_{i=1}^n p(F_i \vert C).
		\end{align*}
		Esto significa que haciendo estas presunciones, la distribución condicional sobre C puede expresarse de la siguiente manera:
		$$p(C \vert F_1,\dots,F_n) = \frac{1}{Z}p(C)\prod_{i=1}^n p(F_i \vert C)$$
		donde $Z$ es un factor que depende sólo de $F_1,\dots , F_n$, es decir, constante si los valores de $F_i$ son conocidos.
		