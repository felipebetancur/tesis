\subsubsection{Teoría de decisión}
	
	La teoría de decisión nos ayuda a tomar decisiones óptimas en situaciones que involucran incertidumbre. La incertidumbre hace referencia a un estado de conocimiento limitado donde es imposible describir con exactitud el estado existente, la salida futura, o más de una posible salida.
	
	Supongamos que tenemos un vector $x$ como entrada junto con el correspondiente vector $t$ de variables objetivo, la meta es predecir $t$ dado un nuevo valor de $x$. En problemas de regresión, $t$ comprenderá variables continuas, mientras que en problemas de clasificación $t$ representará etiquetas de clase. La determinación de $p(x,t)$ dado un conjunto de datos de entrenamiento es un ejemplo de \textit{inferencia} y es típicamente un problema muy difícil. La inferencia, en este caso, hace relación a la estadística inferencial la cual es una parte de la estadística que comprende los métodos y procedimientos que por medio de la inducción determina propiedades de una población estadística, a partir de una pequeña parte de la misma.
	
	Consideremos el siguiente ejemplo, sea $C=\{C_1,\dots,C_k\}$ un conjunto de etiquetas de clase, sea $t \in C$ y sea $x$ un vector de entrada nuevo. Se desea determinar a que clase pertenece $x$. El problema de inferencia involucra determinar la distribución conjunta $p(x,C_k)$, o equivalentemente $p(x,t)$.

	Como se dijo anteriormente, el objetivo es decidir a cual de las $k$ clases pertence el vector de entrada $x$ . Estamos interesados entonces, en las probabilidades de las $k$ clases dado $x$, es decir $p(C_k|x)$, $k=1,\dots,K$. Usando el Teorema de Bayes, estas probabilidades pueden expresarse de la forma:
		\begin{align*}
			p(C_k|x) = \frac{p(x|C_k)p(C_k)}{p(x)}
		\end{align*}

	Ahora podemos interpretar $p(C_k)$ como la probabilidad a priori para la clase $C_k$, y $p(C_k|x)$ como la correspondiente probabilidad a posteriori. Por ejemplo, $p(C_1)$ representa la probabilidad de pertenecer a la clase $C_1$, antes de observar la muestra $x$
	
	Se pueden distinguir dos etapas en el problema de clasificación, la \textit{etapa de inferencia} en el cual se usan los datos para entrenar el modelo para $p(C_k|x)$, y la subsecuente \textit{etapa de decisión} en la cual se usan las probabilidades a posteriori para poder realizar asignaciones óptimas de las clases. Una alternativa, es la de resolver ambos problemas en conjunto y simplemente entrenar una función que mapee las entradas $x$ directamente con las decisiones. Dicha función es llamada \textit{función discriminante}.
	
	De hecho, se pueden identificar tres enfoques diferentes al momento de resolver problemas de decisión. En orden decreciente de complejidad, estos son:
		\begin{enumerate}
			\item Primero, resolver el problema para determinar las densidades condicionales $p(x \vert C_k)$ para cada clase $C_k$ individualmente. También de forma separada, inferir las probabilidades de clases a priori $p(C_k)$. Después, usar el teorema de Bayes en la forma:
			$$p(C_k \vert x) = \frac{p(x \vert C_k)p(C_k)}{p(x)} $$
			para encontrar las probabilidades a posteriori $p(C_k \vert x)$. Como es usual, el denominador en el teorema de Bayes puede ser encontrado en término de las cantidades que aparecen en el numerador, como:
			 $$p(x) = \sum_k p(x \vert C_k)p(C_k) $$
			Equivalentemente, se puede modelar la distribución conjunta $p(x,C_k)$ directamente y después normalizar para obtener las probabilidades a priori. Habiendo encontrado las probabilidades a posteriori, se puede usar la teoría de decisión para determinar la pertenencia a una clase para cada entrada nueva $x$. Los enfoques que explícitamente o implícitamente modelan la distribución de las entradas así también como las salidas son conocidos como \textit{modelos generativos}, debido a que tomando muestras de ellos es posible generar puntos de datos sintéticos en el espacio de entrada.
			\item Primero, resolver el problema de inferencia para determinar las  probabilidades de clase a posteriori $p(C_k \vert x)$, y luego subsecuentemente usar la teoría de decisión para asignar a cada $x$ nueva una de estas clases. Los enfoques que modelan las probabilidades a posteriori directas son llamados \textit{modelos discriminativos}.
			\item Encontrar una función $f(x)$, llamada función discriminante, que mapea directamente cada entrada $x$ con una etiqueta de clase. Por ejemplo, en el caso del problema de dos clases, $f(\cdot)$ puede ser valuada de manera binaria, de manera que $f = 0$ represente a la clase $C_1$ y $f = 1$ represente a la clase $C_2$. En este caso, las probabilidades no toman partido. 
		\end{enumerate}
		
	Consideremos los méritos relativos a estas tres alternativas. El enfoque (1) es el más demandante debido a que involucra encontrar la distribución conjunta tanto de $x$ como de $C_k$. Para muchas aplicaciones, $x$ tendrá alta dimensionalidad, y por consiguiente puede ser necesario un conjunto de entrenamiento grande con el fin de ser capaz de determinar las densidades de clase condicional con una exactitud razonable. Hay que tener en cuenta que la probabilidades a prior $p(C_k)$ de la clase a menudo pueden estimarse simplemente a partir de las proporciones de los punto de datos del conjunto de entrenamiento en cada una de las clases.
		
	Sin embargo, si sólo deseamos realizar decisiones de clasificación, esto conlleva a un gasto de recursos computacionales y una demanda de datos excesiva para encontrar la distribución conjunta $p(x, C_k)$ cuando de hecho, solamente se necesitan las probabilidades a posteriori $p(C_k \vert x)$, las cuales pueden ser obtenidas a través del enfoque (2). 
		
	Un enfoque mucho más simple es (3) en el cual se usa una conjunto de entrenamiento para encontrar una función discriminante $f(x)$ que mapea cada $x$ directamente a una etiqueta de clase, así combinando la inferencia y las etapas de decisión en un simple problema de aprendizaje.
		
	Con la opción (c), sin embargo, se pierde el acceso a las probabilidades a porteriori $p(C_k \vert x)$. 